ZHAW AI1 Module Blog Post

# Comment on AI as normal technology
The following blog post is a reaction to the article called “AI as normal technology”. It presents the prediction that AI is no more extraordinary than other technological innovations from the past such as electricity, the internet or social media. It criticises that the diffusion of AI is measured by the number of users because it is misleading. The diffusion should rather be measured by the application in the industry. By measuring the real value generated the AI hype seems far less warranted. Misinterpreting this AI diffusion is not just a matter of being wrong about predicting the way a technology evolves but overestimating the power and ability causes policies that do not address the real issues at hand.
## The short run
A very interesting example given in the article is about methods used in machine learning. Despite the invention of new approaches for statistical models many applications still rely on old methods. This is because newer methods are more uncontrolled and yield unexpected results which are difficult to detect beforehand.
This example has many similarities with the problem we are facing with LLMs. They struggle to give correct results. While approaches like reflection have shown better results they are not reliable enough. Other approaches like Neural Symbol Systems are other approaches which try to capture knowledge within AI but these worlds seem notoriously difficult to combine. A paper from Apple which went viral this year called "The Illusion of Thinking" suggests that Large Reasoning Models fail to reason genuinely on complex tasks. In their experiments they noticed that the model does not come to new conclusions even if it has the computational resources. This problem has to be solved to ensure that more complex tasks that are currently being performed by humans, can be 

The article makes a strong point on the fact that the application of AI is very much industry dependent. An additional fact which should be considered is that tasks seem simple to automate from the outside, but commonly they are more complex when looked at more closely. For example software engineering is only partly about writing code that an LLM could generate and in many ways it is about human interaction such as when understanding requirements. There is generally no “fits all” solution at hand. While AI agents are a helpful tool in assisting during the different phases, the whole process is very complex and not as simple as it seems from the outside.

Therefore we should be cautious in not overstating the technologies potential in the short run.

## The long run
Despite the downsides of AI currently this does not mean that AI does not have potential that can be unfolded in the long run. While other technologies such as the internet have changed the way we work but took multiple decades to do so, the AI hype in LLMs has the special attributes that it is the first time technology has not just enabled better thinking (e.g. the internet made it possible to make knowledge more widely and timely available) but AI actually augments the thinking process itself. Since language is an interface that comes to us naturally LLMs can assist us in augmenting our thought processes. This not only makes the technology accessible to all but it also spans all industries and facets of life. Such technology which augments human thinking has the potential to accelerate its own development and this is something that we have not yet seen before in technologies.

To summarize I find it reasonable to argue that AI is actually a normal technology like many others. While it does have its own set of challenges and a lot of potential there is no point in fostering fear and calculating the probabilities of unlikely events.
